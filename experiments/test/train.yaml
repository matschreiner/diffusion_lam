training:
  optimizer: 
    name: Adam
    kwargs:
      lr: 0.001
      weight_decay: 0.0001
  scheduler:
    name: StepLR
    kwargs: 
      step_size: 30
      gamma: 0.1
  run:
    steps: 100
    batchsize: 32



